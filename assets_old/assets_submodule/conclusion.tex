\section{Conclusion}
It has been demonstrated that by layering boid flocking behaviour and potential field functions a reinforcement learning agent can be trained to achieve emergent flocking behaviour which could be used to control drone traffic. Although the simulation is simplistic and the machine learning structure may not be optimal, this shows a basic framework is scale-able and could be layered with other reward functions to achieve more complex emergent behaviour.

\subsection{Suggestions for further work}
For further development of this idea one could look at how this system could be scaled further by using a further customised reinforcement learning algorithm. The loss function in this case is quite basic and therefore limits the learning capabilities. Using the Resources available on open AI make it easier to design a capable RL environment to suit specific requirements.\cite{AI} Making use of a Multi-Agent Particle Environment style of RL might also improve learning speeds and scale-ability.\cite{MPE} 

By simulating the environment in 3 dimensions and the addition of obstacles in the form of a city block plan could be used to emulate an environment closer to that intended for the agent.

\clearpage % start appendices on a new page
